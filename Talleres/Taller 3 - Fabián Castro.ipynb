{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ-VfNtOyJbsaxu43Kztf_cv1mgBG6ZIQZEVw&usqp=CAU'>\n",
    "\n",
    "# Procesamiento de Lenguage Natural\n",
    "\n",
    "## Taller #3: Web Scraping\n",
    "`Fabián Castro`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1:\n",
    "\n",
    "- `[15 pts]` Hacer Web Scraping de 10 animales en Wikipedia (en búcle) (lista de animales)\n",
    "- `[10 pts]` Obtener el **encabezado** de cada animal\n",
    "- `[15 pts]` Obtener todos los **textos** que están en las etiquetas de negrilla y cursiva del primer parrafo. Tomar todas las palabras que están en negrilla y cursiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs \n",
    "import urllib.request as urlr\n",
    "import urllib.error\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important functions\n",
    "def downloadSite(url):\n",
    "    \"\"\"\n",
    "    Downloads the html out of the web page corresponding to the url's\n",
    "    \n",
    "    Parameters:\n",
    "    ___________\n",
    "    \n",
    "    url: str\n",
    "    internet direction of the website to download the html content from\n",
    "    \n",
    "    returns:\n",
    "    _______\n",
    "    bytes, str\n",
    "    response body, error\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        request = urlr.Request(url, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "        with urlr.urlopen(request) as webpage:\n",
    "            source = webpage.read()\n",
    "        return source\n",
    "    except urllib.error.HTTPError as e:\n",
    "        # print(f'{e} {url}')\n",
    "        return ''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteLink = \"https://en.wikipedia.org/wiki/\"\n",
    "animalia = ['Killer_whale', 'Giant_squid', 'Portuguese_man_o%27_war', 'Titanosauria', 'Blue-footed_booby',\n",
    "            'Giant_tortoise', 'Megalodon', 'Yellow_cardinal', 'Tardigrade', 'Human', 'Kiwi_(bird)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator for avoidance of RAM clogging, thus letting the music play normaly in the other browser's tab\n",
    "soups = (bs.BeautifulSoup(downloadSite(siteLink + animal),'html.parser')\n",
    "               for animal in animalia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: Killer whale\n",
      "killer whale\n",
      "Orcinus orca\n",
      "orca\n",
      "\n",
      "Header: Giant squid\n",
      "giant squid\n",
      "Architeuthis dux\n",
      "Architeuthidae\n",
      "\n",
      "Header: Portuguese man o' war\n",
      "Portuguese man o' war\n",
      "Physalia physalis\n",
      "man-of-war\n",
      "bluebottle\n",
      "floating terror\n",
      "Pacific man o' war\n",
      "\n",
      "Header: Titanosauria\n",
      "Titanosaurs\n",
      "Titanosauria\n",
      "Patagotitan\n",
      "Argentinosaurus\n",
      "Puertasaurus\n",
      "\n",
      "Header: Blue-footed booby\n",
      "blue-footed booby\n",
      "Sula nebouxii\n",
      "Sula\n",
      "\n",
      "Header: Giant tortoise\n",
      "Giant tortoises\n",
      "\n",
      "Header: Megalodon\n",
      "Megalodon\n",
      "Otodus megalodon\n",
      "Carcharodon carcharias\n",
      "Carcharocles\n",
      "Megaselachus\n",
      "Otodus\n",
      "Procarcharodon\n",
      "Otodus\n",
      "\n",
      "Header: Yellow cardinal\n",
      "yellow cardinal\n",
      "Gubernatrix cristata\n",
      "Gubernatrix\n",
      "Gubernatrix\n",
      "\n",
      "Header: Tardigrade\n",
      "Tardigrades\n",
      "water bears\n",
      "moss piglets\n",
      "little water bears\n",
      "Tardigrada\n",
      "\n",
      "Header: Human\n",
      "Humans\n",
      "Homo sapiens\n",
      "hominids\n",
      "\n",
      "Header: Kiwi (bird)\n",
      "Kiwi\n",
      "KEE-wee\n",
      "kiwis\n",
      "Apteryx\n",
      "Apteryx\n",
      "Apterygidae\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDict = {} #for saving article's header and special tags\n",
    "\n",
    "for soup in soups:\n",
    "    # find article header and prints it if exists\n",
    "    headingTag = soup.find(id = 'firstHeading')\n",
    "    if headingTag is not None:\n",
    "        print('Header:', headingTag.text)\n",
    "        1\n",
    "    # find article first paragraph and prints its bolded and italic words\n",
    "    paragraphTag = soup \\\n",
    "        .find('div', id = 'bodyContent') \\\n",
    "        .find('div', class_ = 'mw-parser-output') \\\n",
    "        .find('p', class_ = None, recursive = False) \\\n",
    "        .find_all(['b','i'])\n",
    "    if paragraphTag is not None:\n",
    "        for elem in paragraphTag:\n",
    "            print(elem.text)\n",
    "    \n",
    "    #save article's header and bolded and italic tags\n",
    "    if headingTag is not None and paragraphTag is not None:\n",
    "        wordDict[headingTag.text] = paragraphTag\n",
    "    print() #extra carriage return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2:\n",
    "- `[10 pts]` Usando regex, reemplazar todos los caracteres especiales del punto anterior por un asterisco (¡Ojo, los espacios se quedan!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "killer whale\n",
      "Orcinus orca\n",
      "orca\n",
      "\n",
      "giant squid\n",
      "Architeuthis dux\n",
      "Architeuthidae\n",
      "\n",
      "Portuguese man o* war\n",
      "Physalia physalis\n",
      "man*of*war\n",
      "bluebottle\n",
      "floating terror\n",
      "Pacific man o* war\n",
      "\n",
      "Titanosaurs\n",
      "Titanosauria\n",
      "Patagotitan\n",
      "Argentinosaurus\n",
      "Puertasaurus\n",
      "\n",
      "blue*footed booby\n",
      "Sula nebouxii\n",
      "Sula\n",
      "\n",
      "Giant tortoises\n",
      "\n",
      "Megalodon\n",
      "Otodus megalodon\n",
      "Carcharodon carcharias\n",
      "Carcharocles\n",
      "Megaselachus\n",
      "Otodus\n",
      "Procarcharodon\n",
      "Otodus\n",
      "\n",
      "yellow cardinal\n",
      "Gubernatrix cristata\n",
      "Gubernatrix\n",
      "Gubernatrix\n",
      "\n",
      "Tardigrades\n",
      "water bears\n",
      "moss piglets\n",
      "little water bears\n",
      "Tardigrada\n",
      "\n",
      "Humans\n",
      "Homo sapiens\n",
      "hominids\n",
      "\n",
      "Kiwi\n",
      "KEE*wee\n",
      "kiwis\n",
      "Apteryx\n",
      "Apteryx\n",
      "Apterygidae\n",
      "\n"
     ]
    }
   ],
   "source": [
    "specChars = '[^a-zA-Z|\\s|\\d]'\n",
    "replacement = '*'\n",
    "\n",
    "#special characters replacement and printing\n",
    "for heading, words in wordDict.items():\n",
    "    for word in words:\n",
    "        print(re.sub(specChars, replacement, word.text))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
